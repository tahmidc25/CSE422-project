# -*- coding: utf-8 -*-
"""422_lab_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16--zZK00Cdm_DRYlTzmQUYrbTHF7kkXi
"""

#Project
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve

df = pd.read_csv('software_quality_dataset.csv')
print("Dataset shape:", df.shape)
print("\nFirst 5 rows:")
print(df.head())
print("\nDataset info:")
print(df.info())

le = LabelEncoder()
df['Has_Unit_Tests'] = le.fit_transform(df['Has_Unit_Tests'])

quality_mapping = {'Low': 0, 'Medium': 1, 'High': 2}
df['Quality_Label'] = df['Quality_Label'].map(quality_mapping)

plt.figure(figsize=(8, 5))
sns.countplot(x='Quality_Label', data=df)
plt.title("Class Distribution")
plt.show()

plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0)
plt.title("Feature Correlation Heatmap")
plt.show()

num_features = ['Lines_of_Code', 'Cyclomatic_Complexity', 'Num_Functions',
                'Code_Churn', 'Comment_Density', 'Num_Bugs', 'Code_Owner_Experience']
imputer = SimpleImputer(strategy='median')
df[num_features] = imputer.fit_transform(df[num_features])

scaler = StandardScaler()
X = df.drop('Quality_Label', axis=1)
y = df['Quality_Label']
X[num_features] = scaler.fit_transform(X[num_features])


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,
                                                    random_state=42,
                                                    stratify=y)

lr = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
print("\nLogistic Regression Results:")
print("Accuracy:", accuracy_score(y_test, y_pred_lr))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_lr, target_names=['Low', 'Medium', 'High']))

dt = DecisionTreeClassifier(random_state=42, max_depth=5)
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)
print("\nDecision Tree Results:")
print("Accuracy:", accuracy_score(y_test, y_pred_dt))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_dt, target_names=['Low', 'Medium', 'High']))

nn = MLPClassifier(hidden_layer_sizes=(64, 32),
                  activation='relu',
                  solver='adam',
                  max_iter=500,
                  random_state=42,
                  early_stopping=True,
                  validation_fraction=0.2)
nn.fit(X_train, y_train)
y_pred_nn = nn.predict(X_test)
print("\nNeural Network Results:")
print("Accuracy:", accuracy_score(y_test, y_pred_nn))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_nn, target_names=['Low', 'Medium', 'High']))

models = ['Logistic Regression', 'Decision Tree', 'Neural Network']
accuracies = [accuracy_score(y_test, y_pred_lr),
              accuracy_score(y_test, y_pred_dt),
              accuracy_score(y_test, y_pred_nn)]

plt.figure(figsize=(10, 6))
sns.barplot(x=models, y=accuracies)
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.ylim(0, 1)
plt.show()

fig, axes = plt.subplots(1, 3, figsize=(18, 5))
cm_lr = confusion_matrix(y_test, y_pred_lr)
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0],
            xticklabels=['Low', 'Medium', 'High'],
            yticklabels=['Low', 'Medium', 'High'])
axes[0].set_title("Logistic Regression")
cm_dt = confusion_matrix(y_test, y_pred_dt)
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Greens', ax=axes[1],
            xticklabels=['Low', 'Medium', 'High'],
            yticklabels=['Low', 'Medium', 'High'])
axes[1].set_title("Decision Tree")
cm_nn = confusion_matrix(y_test, y_pred_nn)
sns.heatmap(cm_nn, annot=True, fmt='d', cmap='Oranges', ax=axes[2],
            xticklabels=['Low', 'Medium', 'High'],
            yticklabels=['Low', 'Medium', 'High'])
axes[2].set_title("Neural Network")
plt.tight_layout()
plt.show()

feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': dt.feature_importances_
}).sort_values('Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance)
plt.title("Decision Tree Feature Importance")
plt.show()

plt.figure(figsize=(10, 8))
for i, model in enumerate([lr, dt, nn]):
    if(hasattr(model, "predict_proba")):
        y_prob = model.predict_proba(X_test)
        for j in range(3):
            fpr, tpr, _ = roc_curve((y_test == j).astype(int), y_prob[:, j])
            auc = roc_auc_score((y_test == j).astype(int), y_prob[:, j])
            plt.plot(fpr, tpr,
                     label=f'{models[i]} - Class {["Low", "Medium", "High"][j]} (AUC = {auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves for Different Models')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 5))
plt.plot(nn.loss_curve_)
plt.title("Neural Network Training Loss")
plt.xlabel("Iterations")
plt.ylabel("Loss")
plt.show()